{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from joblib import dump\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spliting data\n",
    "Splitting to train_train, train_validation & test. The train is 75%, tes 25%. At the train, we splited to train 75%, and validation 25%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.25, random_state=12345)\n",
    "df_train_train, df_train_valid = train_test_split(df_train, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      "calls       3214 non-null float64\n",
      "minutes     3214 non-null float64\n",
      "messages    3214 non-null float64\n",
      "mb_used     3214 non-null float64\n",
      "is_ultra    3214 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2410 entries, 101 to 482\n",
      "Data columns (total 5 columns):\n",
      "calls       2410 non-null float64\n",
      "minutes     2410 non-null float64\n",
      "messages    2410 non-null float64\n",
      "mb_used     2410 non-null float64\n",
      "is_ultra    2410 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 113.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 804 entries, 1415 to 2851\n",
      "Data columns (total 5 columns):\n",
      "calls       804 non-null float64\n",
      "minutes     804 non-null float64\n",
      "messages    804 non-null float64\n",
      "mb_used     804 non-null float64\n",
      "is_ultra    804 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 37.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1807 entries, 2649 to 3027\n",
      "Data columns (total 5 columns):\n",
      "calls       1807 non-null float64\n",
      "minutes     1807 non-null float64\n",
      "messages    1807 non-null float64\n",
      "mb_used     1807 non-null float64\n",
      "is_ultra    1807 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 84.7 KB\n"
     ]
    }
   ],
   "source": [
    "df_train_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 603 entries, 430 to 2673\n",
      "Data columns (total 5 columns):\n",
      "calls       603 non-null float64\n",
      "minutes     603 non-null float64\n",
      "messages    603 non-null float64\n",
      "mb_used     603 non-null float64\n",
      "is_ultra    603 non-null int64\n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 28.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_train_valid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Investigating models\n",
    "\n",
    "Investigating the quality of different models by changing hyperparameters. Briefly describing the findings of the study. Sead 12345.\n",
    "Our problem is a configuration of category problem, if \"is\" or \"not is\" 'Ultra'.\n",
    "\n",
    "Speed: Decision tree - High; Random forest - Low; Logistic regression - High"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_train_features = df_train.drop(['is_ultra'], axis=1)\n",
    "last_train_target = df_train['is_ultra']\n",
    "\n",
    "train_features = df_train_train.drop(['is_ultra'], axis=1)\n",
    "train_target = df_train_train['is_ultra']\n",
    "\n",
    "valid_features = df_train_valid.drop(['is_ultra'], axis=1)\n",
    "valid_target = df_train_valid['is_ultra']\n",
    "\n",
    "test_features = df_train_valid.drop(['is_ultra'], axis=1)\n",
    "test_target = df_train_valid['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "We will check the depth for 1,2,3,4,5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1 : 0.7495854063018242\n",
      "max_depth = 2 : 0.7761194029850746\n",
      "max_depth = 3 : 0.7943615257048093\n",
      "max_depth = 4 : 0.7893864013266998\n",
      "max_depth = 5 : 0.7877280265339967\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,6):\n",
    "    dtc_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    dtc_model.fit(train_features, train_target)\n",
    "    dtc_predicted_valid = dtc_model.predict(valid_features)\n",
    "    print(\"max_depth =\", depth, \": \", end='')\n",
    "    print(accuracy_score(valid_target, dtc_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best depth: 3. Accuracy 0.7943615257048093.\n",
    "\n",
    "### Random Forest Classifier\n",
    "We will check the estimators for 1-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimators = 1 : 0.736318407960199\n",
      "estimators = 2 : 0.7711442786069652\n",
      "estimators = 3 : 0.7661691542288557\n",
      "estimators = 4 : 0.7827529021558872\n",
      "estimators = 5 : 0.7810945273631841\n",
      "estimators = 6 : 0.7993366500829188\n",
      "estimators = 7 : 0.7976782752902156\n",
      "estimators = 8 : 0.7943615257048093\n",
      "estimators = 9 : 0.7943615257048093\n"
     ]
    }
   ],
   "source": [
    "for estimators in range(1,10):\n",
    "    rfc_model = RandomForestClassifier(n_estimators=estimators, random_state=12345)\n",
    "    rfc_model.fit(train_features, train_target)\n",
    "    rfc_predicted_valid = rfc_model.predict(valid_features)\n",
    "    print(\"estimators =\", estimators, \": \", end='')\n",
    "    print(accuracy_score(valid_target, rfc_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best estimator: 6. Accuracy 0.7993366500829188.\n",
    "\n",
    "###  Logistic Regression Classifier\n",
    "We will check the max iteration for 50-150, by jumps of 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations = 50 : 0.7330016583747927\n",
      "iterations = 75 : 0.7330016583747927\n",
      "iterations = 100 : 0.7330016583747927\n",
      "iterations = 125 : 0.7330016583747927\n",
      "iterations = 150 : 0.7330016583747927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for iterations in range(50,151,25):\n",
    "    lrc_model = LogisticRegression(max_iter=iterations, random_state=12345)\n",
    "    lrc_model.fit(train_features, train_target)\n",
    "    lrc_predicted_valid = lrc_model.predict(valid_features)\n",
    "    print(\"iterations =\", iterations, \": \", end='')\n",
    "    #     model.score(features_valid, target_valid)\n",
    "    print(accuracy_score(valid_target, lrc_predicted_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All iterations had same accuracy of 0.7330016583747927.\n",
    "We will choose the default of 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Checking the model on the test set\n",
    "Checking the quality of the model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dtc_model = DecisionTreeClassifier(max_depth=3, random_state=12345)\n",
    "final_rfc_model = RandomForestClassifier(n_estimators=6, random_state=12345)\n",
    "final_lrc_model = LogisticRegression(max_iter=100, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=12345, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dtc_model.fit(last_train_features,last_train_target)\n",
    "final_rfc_model.fit(last_train_features,last_train_target)\n",
    "final_lrc_model.fit(last_train_features,last_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_predictions = final_dtc_model.predict(test_features)\n",
    "rfc_predictions = final_rfc_model.predict(test_features)\n",
    "lrc_predictions = final_lrc_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 0.802653399668325\n",
      "Random Forest Classifier Accuracy: 0.9734660033167496\n",
      "Logistic Regression Classifier Accuracy: 0.6965174129353234\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Classifier Accuracy: \", end='')\n",
    "print(accuracy_score(test_target, dtc_predictions))\n",
    "\n",
    "print(\"Random Forest Classifier Accuracy: \", end='')\n",
    "print(accuracy_score(test_target, rfc_predictions))\n",
    "\n",
    "print(\"Logistic Regression Classifier Accuracy: \", end='')\n",
    "print(accuracy_score(test_target, lrc_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best classifier is the Random Forest classifier with an accuracy of 0.9734660033167496. The model is with a number of estimators = 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Sanity check of the model\n",
    "\n",
    "My conclusion is that the Random Forest and the Decision Tree classifiers were underfit, and the Logistic Regression classifier was overfitted.\n",
    "Yet, the results for the Decision Tree and the Logistic Regression are low. It could be that the categories are not well differed, at least not by a line that can separate both groups. Or either, the users have pretty the same numbers.\n",
    "Something else it could be that the two bad classifiers do not bring the connection between two features, that maybe the Random Forest classifier can do."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
